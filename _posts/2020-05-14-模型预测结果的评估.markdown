---
layout:     post
title:      "ML5--æ¨¡å‹é¢„æµ‹ç»“æœçš„è¯„ä¼°"
subtitle:   "æœºå™¨å­¦ä¹ ç¬¬äº”è¯¾"
date:       2020-05-14 00:10:00
author:     "yan"
header-img: "img/image_back_04.jpg"
top-img: "/img/202005/0514003.png"
catalog: true
tags:
    - æœºå™¨å­¦ä¹ 
---
>'æ²¡æœ‰æµ‹é‡ï¼Œå°±æ²¡æœ‰ç§‘å­¦'è¿™æ˜¯ç§‘å­¦å®¶é—¨æ·åˆ—å¤«çš„åè¨€ã€‚åœ¨è®¡ç®—æœºç§‘å­¦ç‰¹åˆ«æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸä¸­ï¼Œå¯¹æ¨¡å‹çš„è¯„ä¼°åŒæ ·è‡³å…³é‡è¦ï¼Œåªæœ‰é€‰æ‹©ä¸é—®é¢˜ç›¸åŒ¹é…çš„è¯„ä¼°æ–¹æ³•ï¼Œæ‰èƒ½å¿«é€Ÿåœ°å‘ç°æ¨¡å‹é€‰æ‹©æˆ–è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°çš„é—®é¢˜ï¼Œè¿­ä»£åœ°å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚æ¨¡å‹è¯„ä¼°ä¸»è¦åˆ†ä¸ºç¦»çº¿è¯„ä¼°å’Œåœ¨çº¿è¯„ä¼°ä¸¤ä¸ªé˜¶æ®µã€‚é’ˆå¯¹åˆ†ç±»ã€æ’åºã€å›å½’ã€åºåˆ—é¢„æµ‹ç­‰ä¸åŒç±»å‹çš„æœºå™¨å­¦ä¹ é—®é¢˜ï¼Œè¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ä¹Ÿæœ‰æ‰€ä¸åŒã€‚çŸ¥é“æ¯ç§è¯„ä¼°æŒ‡æ ‡çš„ç²¾ç¡®å®šä¹‰ã€æœ‰é’ˆå¯¹æ€§åœ°é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ã€æ›´å…·è¯„ä¼°æŒ‡æ ‡çš„åé¦ˆè¿›è¡Œæ¨¡å‹è°ƒæ•´ï¼Œè¿™äº›éƒ½æ˜¯æ¨¡å‹è¯„ä¼°é˜¶æ®µçš„å…³é”®é—®é¢˜
# è¯„ä¼°æŒ‡æ ‡
## 1. accuracy_score
&emsp;&emsp;åˆ†ç±»å‡†ç¡®ç‡åˆ†æ•°æ˜¯æŒ‡æ‰€æœ‰åˆ†ç±»æ­£ç¡®çš„ç™¾åˆ†æ¯”ã€‚åˆ†ç±»å‡†ç¡®ç‡è¿™ä¸€è¡¡é‡åˆ†ç±»å™¨çš„æ ‡å‡†æ¯”è¾ƒå®¹æ˜“ç†è§£ï¼Œä½†æ˜¯å®ƒä¸èƒ½å‘Šè¯‰ä½ å“åº”å€¼çš„æ½œåœ¨åˆ†å¸ƒï¼Œå¹¶ä¸”å®ƒä¹Ÿä¸èƒ½å‘Šè¯‰ä½ åˆ†ç±»å™¨çŠ¯é”™çš„ç±»å‹ã€‚

&emsp;&emsp;å½¢å¼:
**sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)**

&emsp;&emsp;normalizeï¼šé»˜è®¤å€¼ä¸ºTrueï¼Œè¿”å›æ­£ç¡®åˆ†ç±»çš„æ¯”ä¾‹ï¼›å¦‚æœä¸ºFalseï¼Œè¿”å›æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æ•°

&emsp;&emsp;ç¤ºä¾‹:
```
>>>import numpy as np  
>>>from sklearn.metrics import accuracy_score  
>>>y_pred = [0, 2, 1, 3]  
>>>y_true = [0, 1, 2, 3]  
>>>accuracy_score(y_true, y_pred)  
0.5  
>>>accuracy_score(y_true, y_pred, normalize=False)  
2  
```

## 2. recall_score
&emsp;&emsp;å¬å›ç‡ =æå–å‡ºçš„æ­£ç¡®ä¿¡æ¯æ¡æ•° /æ ·æœ¬ä¸­çš„ä¿¡æ¯æ¡æ•°ã€‚é€šä¿—åœ°è¯´ï¼Œå°±æ˜¯æ‰€æœ‰å‡†ç¡®çš„æ¡ç›®æœ‰å¤šå°‘è¢«æ£€ç´¢å‡ºæ¥äº†ã€‚

&emsp;&emsp;å½¢å¼ï¼š
**klearn.metrics.recall_score(y_true, y_pred, labels=None, pos_label=1,average='binary', sample_weight=None)**

&emsp;&emsp;å‚æ•°average : string, [None, â€˜microâ€™, â€˜macroâ€™(default), â€˜samplesâ€™, â€˜weightedâ€™]

&emsp;&emsp;å°†ä¸€ä¸ªäºŒåˆ†ç±»matricsæ‹“å±•åˆ°å¤šåˆ†ç±»æˆ–å¤šæ ‡ç­¾é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®çœ‹æˆå¤šä¸ªäºŒåˆ†ç±»é—®é¢˜çš„é›†åˆï¼Œæ¯ä¸ªç±»éƒ½æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è·¨å¤šä¸ªåˆ†ç±»è®¡ç®—æ¯ä¸ªäºŒåˆ†ç±»metricså¾—åˆ†çš„å‡å€¼ï¼Œè¿™åœ¨ä¸€äº›æƒ…å†µä¸‹å¾ˆæœ‰ç”¨ã€‚ä½ å¯ä»¥ä½¿ç”¨averageå‚æ•°æ¥æŒ‡å®šã€‚

&emsp;&emsp;macroï¼šè®¡ç®—äºŒåˆ†ç±»metricsçš„å‡å€¼ï¼Œä¸ºæ¯ä¸ªç±»ç»™å‡ºç›¸åŒæƒé‡çš„åˆ†å€¼ã€‚å½“å°ç±»å¾ˆé‡è¦æ—¶ä¼šå‡ºé—®é¢˜ï¼Œå› ä¸ºè¯¥macro-avergingæ–¹æ³•æ˜¯å¯¹æ€§èƒ½çš„å¹³å‡ã€‚å¦ä¸€æ–¹é¢ï¼Œè¯¥æ–¹æ³•å‡è®¾æ‰€æœ‰åˆ†ç±»éƒ½æ˜¯ä¸€æ ·é‡è¦çš„ï¼Œå› æ­¤macro-averagingæ–¹æ³•ä¼šå¯¹å°ç±»çš„æ€§èƒ½å½±å“å¾ˆå¤§ã€‚

&emsp;&emsp;weighted:å¯¹äºä¸å‡è¡¡æ•°é‡çš„ç±»æ¥è¯´ï¼Œè®¡ç®—äºŒåˆ†ç±»metricsçš„å¹³å‡ï¼Œé€šè¿‡åœ¨æ¯ä¸ªç±»çš„scoreä¸Šè¿›è¡ŒåŠ æƒå®ç°ã€‚

&emsp;&emsp;microï¼šç»™å‡ºäº†æ¯ä¸ªæ ·æœ¬ç±»ä»¥åŠå®ƒå¯¹æ•´ä¸ªmetricsçš„è´¡çŒ®çš„pairï¼ˆsample-weightï¼‰ï¼Œè€Œéå¯¹æ•´ä¸ªç±»çš„metricsæ±‚å’Œï¼Œå®ƒä¼šæ¯ä¸ªç±»çš„metricsä¸Šçš„æƒé‡åŠå› å­è¿›è¡Œæ±‚å’Œï¼Œæ¥è®¡ç®—æ•´ä¸ªä»½é¢ã€‚Micro-averagingæ–¹æ³•åœ¨å¤šæ ‡ç­¾ï¼ˆmultilabelï¼‰é—®é¢˜ä¸­è®¾ç½®ï¼ŒåŒ…å«å¤šåˆ†ç±»ï¼Œæ­¤æ—¶ï¼Œå¤§ç±»å°†è¢«å¿½ç•¥ã€‚

&emsp;&emsp;samplesï¼šåº”ç”¨åœ¨multilabelé—®é¢˜ä¸Šã€‚å®ƒä¸ä¼šè®¡ç®—æ¯ä¸ªç±»ï¼Œç›¸åï¼Œå®ƒä¼šåœ¨è¯„ä¼°æ•°æ®ä¸­ï¼Œé€šè¿‡è®¡ç®—çœŸå®ç±»å’Œé¢„æµ‹ç±»çš„å·®å¼‚çš„metricsï¼Œæ¥æ±‚å¹³å‡ï¼ˆsample_weight-weightedï¼‰

&emsp;&emsp;averageï¼šaverage=Noneå°†è¿”å›ä¸€ä¸ªæ•°ç»„ï¼Œå®ƒåŒ…å«äº†æ¯ä¸ªç±»çš„å¾—åˆ†.
ç¤ºä¾‹:
```
>>>from sklearn.metrics import recall_score  
>>>y_true = [0, 1, 2, 0, 1, 2]  
>>>y_pred = [0, 2, 1, 0, 0, 1]  
>>>recall_score(y_true, y_pred, average='macro')   
0.33...  
>>>recall_score(y_true, y_pred, average='micro')   
0.33...  
>>>recall_score(y_true, y_pred, average='weighted')   
0.33...  
>>>recall_score(y_true, y_pred, average=None)  
array([1.,  0., 0.])  
```

## 3. f1_score
&emsp;&emsp;F1åˆ†æ•°æ˜¯ç²¾åº¦å’Œå¬å›ç‡çš„è°æ³¢å¹³å‡å€¼ï¼Œæ­£å¸¸çš„å¹³å‡å€¼å¹³ç­‰å¯¹å¾…æ‰€æœ‰çš„å€¼ï¼Œè€Œè°æ³¢å¹³å‡å€¼å›ç»™äºˆè¾ƒä½çš„å€¼æ›´é«˜çš„æƒé‡ï¼Œå› æ­¤ï¼Œåªæœ‰å½“å¬å›ç‡å’Œç²¾åº¦éƒ½å¾ˆé«˜æ—¶ï¼Œåˆ†ç±»å™¨æ‰èƒ½å¾—åˆ°è¾ƒé«˜çš„F1åˆ†æ•°ã€‚
&emsp;&emsp;å…¶ä¸­ï¼ŒPä»£è¡¨Precisionï¼ŒRä»£è¡¨Recallã€‚
<div align="center"> <img src="/img/202005/0514001.png"/> </div>
&emsp;&emsp;F1-ScoreæŒ‡æ ‡ç»¼åˆäº†Precisionä¸Recallçš„äº§å‡ºçš„ç»“æœã€‚F1-Scoreçš„å–å€¼èŒƒå›´ä»0åˆ°1çš„ï¼Œ1ä»£è¡¨æ¨¡å‹çš„è¾“å‡ºæœ€å¥½ï¼Œ0ä»£è¡¨æ¨¡å‹çš„è¾“å‡ºç»“æœæœ€å·®ã€‚
&emsp;&emsp;ç¤ºä¾‹:
```
>>>from sklearn.metrics import recall_score  
>>>y_true = [0, 1, 2, 0, 1, 2]  
>>>y_pred = [0, 2, 1, 0, 0, 1]  
>>>f1_score(y_true, y_pred, average='macro')   
0.57...
```

## 4. rocæ›²çº¿
&emsp;&emsp;äºŒå€¼åˆ†ç±»å™¨æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸä¸­æœ€å¸¸è§ä¹Ÿæ˜¯åº”ç”¨æœ€å¹¿æ³›çš„åˆ†ç±»å™¨ã€‚è¯„ä»·äºŒå€¼åˆ†ç±»å™¨çš„æŒ‡æ ‡å¾ˆå¤šï¼Œæ¯”å¦‚precision,recall,F1 score,P-Ræ›²çº¿ç­‰ï¼Œä½†å‘ç°è¿™äº›æŒ‡æ ‡æˆ–å¤šæˆ–å°‘åªèƒ½åæ˜ æ¨¡å‹åœ¨æŸä¸€æ–¹é¢çš„æ€§èƒ½ï¼Œç›¸æ¯”è€Œè¨€ï¼ŒROCæ›²çº¿åˆ™æœ‰å¾ˆå¤šä¼˜ç‚¹ï¼Œç»å¸¸ä½œä¸ºè¯„ä¼°äºŒå€¼åˆ†ç±»å™¨æœ€é‡è¦çš„æŒ‡æ ‡ä¹‹ä¸€

&emsp;&emsp;ROCæ›²çº¿æ˜¯Receiver Operating Characteristic Curveçš„ç®€ç§°ï¼Œä¸­æ–‡åä¸º'å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿'

&emsp;&emsp;ROCæ›²çº¿çš„æ¨ªåæ ‡ä¸ºå‡é˜³æ€§ç‡(FPR),çºµåæ ‡ä¸ºçœŸé˜³æ€§ç‡(TPR)ï¼ŒFPRå’ŒTPRçš„è®¡ç®—æ–¹æ³•åˆ†åˆ«ä¸º:

**ğ¹ğ‘ƒğ‘…=ğ¹ğ‘ƒğ‘**
**ğ‘‡ğ‘ƒğ‘…=ğ‘‡ğ‘ƒğ‘ƒ**

&emsp;&emsp;Pæ˜¯çœŸå®çš„æ­£æ ·æœ¬æ•°é‡ï¼ŒNæ˜¯çœŸå®çš„è´Ÿæ ·æœ¬æ•°é‡ï¼ŒTPæ˜¯Pä¸ªæ­£æ ·æœ¬ä¸­è¢«åˆ†ç±»å™¨é¢„æµ‹ä¸ºæ­£æ ·æœ¬çš„ä¸ªæ•°ï¼ŒFPä¸ºNä¸ªè´Ÿæ ·æœ¬ä¸­è¢«é¢„æµ‹ä¸ºæ­£æ ·æœ¬çš„ä¸ªæ•°ã€‚
&emsp;&emsp;ç¤ºä¾‹ï¼š
```
>>>import numpy as np  
>>>from sklearn import metrics  
>>>y = np.array([1, 1, 2, 2])  
>>>scores = np.array([0.1, 0.4, 0.35, 0.8])  
>>>fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)  
>>>fpr  
array([0. ,  0.5,  0.5, 1. ])  
>>>tpr  
array([0.5,  0.5,  1. , 1. ])  
>>>thresholds  
array([0.8 ,  0.4 ,  0.35, 0.1 ])  
>>>from sklearn.metrics import auc   
>>>metrics.auc(fpr, tpr)   
0.75 
```
#### ROCæ›²çº¿ç»˜åˆ¶
##### åˆ›å»ºæ•°æ®é›†
```
import pandas as pd

column_name = ['çœŸå®æ ‡ç­¾','æ¨¡å‹è¾“å‡ºæ¦‚ç‡']
datasets = [['p',0.9],['p',0.8],['n',0.7],['p',0.6],
           ['p',0.55],['p',0.54],['n',0.53],['n',0.52],
           ['p',0.51],['n',0.505],['p',0.4],['p',0.39],
           ['p',0.38],['n',0.37],['n',0.36],['n',0.35],
           ['p',0.34],['n',0.33],['p',0.30],['n',0.1]]

data = pd.DataFrame(datasets,index = [i for i in range(1,21,1)],columns=column_name)
print(data)
   çœŸå®æ ‡ç­¾  æ¨¡å‹è¾“å‡ºæ¦‚ç‡
1     p   0.900
2     p   0.800
3     n   0.700
4     p   0.600
5     p   0.550
6     p   0.540
7     n   0.530
8     n   0.520
9     p   0.510
10    n   0.505
11    p   0.400
12    p   0.390
13    p   0.380
14    n   0.370
15    n   0.360
16    n   0.350
17    p   0.340
18    n   0.330
19    p   0.300
20    n   0.100
```
##### ç»˜åˆ¶ROCæ›²çº¿
```
# è®¡ç®—å„ç§æ¦‚ç‡æƒ…å†µä¸‹å¯¹åº”çš„(å‡é˜³ç‡ï¼ŒçœŸé˜³ç‡)
points = {0.1:[1,1],0.3:[0.9,1],0.33:[0.9,0.9],0.34:[0.8,0.9],0.35:[0.8,0.8],
        0.36:[0.7,0.8],0.37:[0.6,0.8],0.38:[0.5,0.8],0.39:[0.5,0.7],0.40:[0.4,0.7],
        0.505:[0.4,0.6],0.51:[0.3,0.6],0.52:[0.3,0.5],0.53:[0.2,0.5],0.54:[0.1,0.5],
        0.55:[0.1,0.4],0.6:[0.1,0.3],0.7:[0.1,0.2],0.8:[0,0.2],0.9:[0,0.1]}
X = []
Y = []
for value in points.values():
        X.append(value[0])
        Y.append(value[1])
        
import matplotlib.pyplot as plt

plt.scatter(X,Y,c = 'r',marker = 'o')
plt.plot(X,Y)

plt.xlim(0,1)
plt.ylim(0,1)
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.show()
```
<div align="center"> <img src="/img/202005/0514002.png"/> </div>
&emsp;&emsp;AUCæŒ‡ROCæ›²çº¿ä¸‹çš„é¢ç§¯å¤§å°ï¼Œè¯¥å€¼èƒ½å¤Ÿé‡åŒ–åœ°åæ˜ åŸºäºROCæ›²çº¿è¡¡é‡å‡ºçš„æ¨¡å‹æ€§èƒ½,AUCè¶Šå¤§è¯´æ˜åˆ†ç±»å™¨è¶Šå¯èƒ½æŠŠçœŸæ­£çš„æ­£æ ·æœ¬æ’åœ¨å‰é¢ï¼Œåˆ†ç±»æ€§èƒ½è¶Šå¥½

&emsp;&emsp;ROCæ›²çº¿ç›¸æ¯”P-Ræ›²çº¿ï¼Œå½“æ­£è´Ÿæ ·æœ¬çš„åˆ†å¸ƒå‘ç”Ÿå˜åŒ–æ—¶ï¼ŒROCæ›²çº¿çš„å½¢çŠ¶èƒ½å¤Ÿä¿å­˜åŸºæœ¬ä¸å˜ï¼Œè€ŒP-Ræ›²çº¿çš„å½¢çŠ¶ä¸€èˆ¬ä¼šå‘ç”Ÿæ¿€çƒˆçš„å˜åŒ–ï¼Œè¿™ä¸ªç‰¹ç‚¹è®©ROCæ›²çº¿èƒ½å¤Ÿå°½é‡é™ä½ä¸åŒæµ‹è¯•é›†å¸¦æ¥çš„å¹²æ‰°ï¼Œæ›´åŠ å®¢è§‚åœ°è¡¡é‡æ¨¡å‹æœ¬èº«çš„æ€§èƒ½
## 5. Auc
&emsp;&emsp;è®¡ç®—AUCå€¼ï¼Œå…¶ä¸­x,yåˆ†åˆ«ä¸ºæ•°ç»„å½¢å¼ï¼Œæ ¹æ®(xi,yi)åœ¨åæ ‡ä¸Šçš„ç‚¹ï¼Œç”Ÿæˆçš„æ›²çº¿ï¼Œç„¶åè®¡ç®—AUCå€¼ï¼›

&emsp;&emsp;å½¢å¼ï¼š
**sklearn.metrics.auc(x, y, reorder=False)**

## 6. roc_auc_score
&emsp;&emsp;ç›´æ¥æ ¹æ®çœŸå®å€¼ï¼ˆå¿…é¡»æ˜¯äºŒå€¼ï¼‰ã€é¢„æµ‹å€¼ï¼ˆå¯ä»¥æ˜¯0/1,ä¹Ÿå¯ä»¥æ˜¯probaå€¼ï¼‰è®¡ç®—å‡ºaucå€¼ï¼Œä¸­é—´è¿‡ç¨‹çš„rocè®¡ç®—çœç•¥ã€‚

&emsp;&emsp;å½¢å¼ï¼š
**sklearn.metrics.roc_auc_score(y_true, y_score, average='macro', sample_weight=None)**

&emsp;&emsp;average : string, [None, â€˜microâ€™, â€˜macroâ€™(default), â€˜samplesâ€™, â€˜weightedâ€™]

&emsp;&emsp;ç¤ºä¾‹ï¼š
```
>>>import numpy as np  
>>>from sklearn.metrics import roc_auc_score  
>>>y_true = np.array([0, 0, 1, 1])  
>>>y_scores = np.array([0.1, 0.4, 0.35, 0.8])  
>>>roc_auc_score(y_true, y_scores)  
0.75  
```

## 7. confusion_matrix
&emsp;&emsp;ç”¨ä¸€ä¸ªä¾‹å­æ¥ç†è§£æ··æ·†çŸ©é˜µï¼š
&emsp;&emsp;å‡è®¾æœ‰ä¸€ä¸ªç”¨æ¥å¯¹çŒ«ï¼ˆcatsï¼‰ã€ç‹—ï¼ˆdogsï¼‰ã€å…”å­ï¼ˆrabbitsï¼‰è¿›è¡Œåˆ†ç±»çš„ç³»ç»Ÿï¼Œæ··æ·†çŸ©é˜µå°±æ˜¯ä¸ºäº†è¿›ä¸€æ­¥åˆ†ææ€§èƒ½è€Œå¯¹è¯¥ç®—æ³•æµ‹è¯•ç»“æœåšå‡ºçš„æ€»ç»“ã€‚å‡è®¾æ€»å…±æœ‰ 27 åªåŠ¨ç‰©ï¼š8åªçŒ«ï¼Œ 6æ¡ç‹—ï¼Œ 13åªå…”å­ã€‚ç»“æœçš„æ··æ·†çŸ©é˜µå¦‚ä¸‹å›¾ï¼š
<div align="center"> <img src="/img/202005/0514003.png"/> </div>
&emsp;&emsp;åœ¨è¿™ä¸ªæ··æ·†çŸ©é˜µä¸­ï¼Œå®é™…æœ‰ 8åªçŒ«ï¼Œä½†æ˜¯ç³»ç»Ÿå°†å…¶ä¸­3åªé¢„æµ‹æˆäº†ç‹—ï¼›å¯¹äº 6æ¡ç‹—ï¼Œå…¶ä¸­æœ‰ 1æ¡è¢«é¢„æµ‹æˆäº†å…”å­ï¼Œ2æ¡è¢«é¢„æµ‹æˆäº†çŒ«ã€‚ä»æ··æ·†çŸ©é˜µä¸­æˆ‘ä»¬å¯ä»¥çœ‹å‡ºç³»ç»Ÿå¯¹äºåŒºåˆ†çŒ«å’Œç‹—å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä½†æ˜¯åŒºåˆ†å…”å­å’Œå…¶ä»–åŠ¨ç‰©çš„æ•ˆæœè¿˜æ˜¯ä¸é”™çš„ã€‚æ‰€æœ‰æ­£ç¡®çš„é¢„æµ‹ç»“æœéƒ½åœ¨å¯¹è§’çº¿ä¸Šï¼Œæ‰€ä»¥ä»æ··æ·†çŸ©é˜µä¸­å¯ä»¥å¾ˆæ–¹ä¾¿ç›´è§‚çš„çœ‹å‡ºå“ªé‡Œæœ‰é”™è¯¯ï¼Œå› ä¸ºä»–ä»¬å‘ˆç°åœ¨å¯¹è§’çº¿å¤–é¢ã€‚

# è¯„ä¼°æ–¹æ³•
## 1. ä½¿ç”¨numpyè®¡ç®—
```
import numpy as np
 
y_true = np.array([0, 1, 1, 0, 1, 0])
y_pred = np.array([1, 1, 1, 0, 0, 1])
 
# true positive
TP = np.sum(np.multiply(y_true, y_pred))
print(TP)
 
# false positive
FP = np.sum(np.logical_and(np.equal(y_true, 0), np.equal(y_pred, 1)))
print(FP)
 
# false negative
FN = np.sum(np.logical_and(np.equal(y_true, 1), np.equal(y_pred, 0)))
print(FN)
 
# true negative
TN = np.sum(np.logical_and(np.equal(y_true, 0), np.equal(y_pred, 0)))
print(TN)
```
è¾“å‡ºç»“æœï¼š
```
2
2
1
1
```
## 2. ä½¿ç”¨tensorflowè®¡ç®—
```
import tensorflow as tf
 
sess = tf.Session()
 
y_true = tf.constant([0, 1, 1, 0, 1, 0])
y_pred = tf.constant([1, 1, 1, 0, 0, 1])
 
# true positive
TP = tf.reduce_sum(tf.multiply(y_true, y_pred))
print(sess.run(TP))
 
# false positive
FP = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 1)), tf.int32))
print(sess.run(FP))
 
# false negative
FN = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 0)), tf.int32))
print(sess.run(FN))
 
# true negative
TN = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 0)), tf.int32))
print(sess.run(TN))
```
è¾“å‡ºç»“æœï¼š
```
2
2
1
1
```
## 3. ä½¿ç”¨sklearnçš„metricsæ¨¡å—è®¡ç®—
### 3.1 æ•°æ®æ˜¯listç±»å‹
```
from sklearn.metrics import precision_score, recall_score, f1_score
 
y_true = [0, 1, 1, 0, 1, 0]
y_pred = [1, 1, 1, 0, 0, 1]
 
p = precision_score(y_true, y_pred, average='binary')
r = recall_score(y_true, y_pred, average='binary')
f1score = f1_score(y_true, y_pred, average='binary')
 
print(p)
print(r)
print(f1score)
```
è¾“å‡ºç»“æœï¼š
```
0.5
0.666666666667
0.571428571429
```
### 3.2 æ•°æ®æ˜¯ndarrayç±»å‹
```
from sklearn.metrics import precision_score, recall_score, f1_score
import numpy as np
 
y_true = np.array([[0, 1, 1], 
                   [0, 1, 0]])
y_pred = np.array([[1, 1, 1], 
                   [0, 0, 1]])
 
y_true = np.reshape(y_true, [-1])
y_pred = np.reshape(y_pred, [-1])
 
p = precision_score(y_true, y_pred, average='binary')
r = recall_score(y_true, y_pred, average='binary')
f1score = f1_score(y_true, y_pred, average='binary')
 
print(p)
print(r)
print(f1score)
```
è¾“å‡ºç»“æœï¼š
```
0.5
0.666666666667
0.571428571429
```
